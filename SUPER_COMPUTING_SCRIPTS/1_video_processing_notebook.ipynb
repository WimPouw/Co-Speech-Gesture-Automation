{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a077198",
   "metadata": {},
   "source": [
    "# <strong>Video Processing Notebook |</strong>\n",
    "##### <strong>Author:</strong> <u>Walter Dych</u> <em>(walterpdych@gmail.com)</em>\n",
    "##### <strong>Edits/Documentation:</strong> <u>Karee Garvin</u> <em>(kgarvin@fas.harvard.edu)</em>\n",
    "\n",
    "This notebook serves the purpose of video processing using various computational techniques.\n",
    "\n",
    "### <strong>Requirements</strong>\n",
    "\n",
    "To run this notebook, you will need the following Python packages:\n",
    "\n",
    "- mediapipe\n",
    "- opencv-python\n",
    "- pandas\n",
    "- matplotlib\n",
    "\n",
    "You can install these packages using pip:\n",
    "```shell\n",
    "    pip install mediapipe opencv-python pandas matplotlib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ddf29",
   "metadata": {},
   "source": [
    "### <strong>Importing Libraries</strong>\n",
    "Here, we import essential libraries:\n",
    "- `cv2`: OpenCV for image and video processing\n",
    "- `mediapipe`: Google\"s MediaPipe for pose estimation\n",
    "- `os`: For operating system related tasks\n",
    "- `pandas`: For DataFrame support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca871f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed58070",
   "metadata": {},
   "source": [
    "### <strong>Setting Parameters</strong>\n",
    "In this section, you can modify the following parameters:\n",
    "- `MODEL`: Choose between Lite model (`1`) and Full model (`2`). Lite Model (`1`) is the  `Default`.\n",
    "- `video_path`: Path to the video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 2  # 1 = Lite model, 2 = Full model\n",
    "video_path = \"C:/Users/cosmo/Desktop/Random Scripts/Co-Speech Gesture Automation/Co-Speech-Gesture-Automation/VIDEO_FILES/5003_I.MOV\"  # Add your video file path here\n",
    "\n",
    "if os.path.exists(video_path) == True:\n",
    "    print(f\"{video_path} is a valid file. Proceed with processing.\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"{video_path} does not exist. Try adding the entire file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1e2c4",
   "metadata": {},
   "source": [
    "### <strong>Initialization</strong>\n",
    "This part initializes MediaPipe components used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34058d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe components\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3130a9",
   "metadata": {},
   "source": [
    "### <strong>Processing Loop</strong>\n",
    "The core logic of video processing is performed in this loop.\n",
    "This code block reads in a video file and extracts pose landmarks from each frame of the video using the `mediapipe` and `opencv-python` libraries. The pose landmarks are then stored in a DataFrame along with the corresponding time stamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa76350",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Processing video at {video_path}\")\n",
    "with mp_holistic.Holistic(static_image_mode=False, model_complexity=MODEL) as holistic:\n",
    "    # Initialize DataFrame to store data\n",
    "    data = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        # Append data to list\n",
    "        time_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        \n",
    "        # Dictionary to store data\n",
    "        if results.pose_landmarks is not None:\n",
    "            right_shoulder_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER].x\n",
    "            right_shoulder_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER].y\n",
    "            left_shoulder_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER].x\n",
    "            left_shoulder_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER].y\n",
    "            right_elbow_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ELBOW].x\n",
    "            right_elbow_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ELBOW].y\n",
    "            left_elbow_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ELBOW].x\n",
    "            left_elbow_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ELBOW].y\n",
    "            right_wrist_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_WRIST].x\n",
    "            right_wrist_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_WRIST].y\n",
    "            left_wrist_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_WRIST].x\n",
    "            left_wrist_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_WRIST].y\n",
    "            right_eye_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_EYE].x\n",
    "            right_eye_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_EYE].y\n",
    "            left_eye_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE].x\n",
    "            left_eye_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE].y\n",
    "            nose_x = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x\n",
    "            nose_y = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y\n",
    "            \n",
    "            data.append([time_ms, right_shoulder_x, right_shoulder_y, left_shoulder_x, left_shoulder_y, right_elbow_x, right_elbow_y, left_elbow_x, left_elbow_y, right_wrist_x, right_wrist_y, left_wrist_x, left_wrist_y, right_eye_x, right_eye_y, left_eye_x, left_eye_y, nose_x, nose_y])\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"time_ms\", \n",
    "    \"right_shoulder_x\", \"right_shoulder_y\", \n",
    "    \"left_shoulder_x\", \"left_shoulder_y\", \n",
    "    \"right_elbow_x\", \"right_elbow_y\", \n",
    "    \"left_elbow_x\", \"left_elbow_y\", \n",
    "    \"right_wrist_x\", \"right_wrist_y\", \n",
    "    \"left_wrist_x\", \"left_wrist_y\", \n",
    "    \"right_eye_x\", \"right_eye_y\", \n",
    "    \"left_eye_x\", \"left_eye_y\",\n",
    "    \"nose_x\", \"nose_y\"\n",
    "    ])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691108d0",
   "metadata": {},
   "source": [
    "### <strong>Data Output</strong>\n",
    "Finally, the processed data is stored in a DataFrame and saved as a pickle file and csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print DataFrame shape\n",
    "print(f\"DataFrame Head: {df.head()}\")\n",
    "\n",
    "# Save DataFrame as pickle file\n",
    "pickle_file_name = \"C:/Users/cosmo/Desktop/Random Scripts/Co-Speech Gesture Automation/Co-Speech-Gesture-Automation/MOTION_TRACKING_FILES/\" + os.path.splitext(os.path.basename(video_path))[0] + \"_keypoints.pkl\"\n",
    "df.to_pickle(pickle_file_name)\n",
    "print(f\"DataFrame saved as {pickle_file_name}\")\n",
    "\n",
    "# Save DataFrame as CSV file\n",
    "csv_file_name = \"C:/Users/cosmo/Desktop/Random Scripts/Co-Speech Gesture Automation/Co-Speech-Gesture-Automation/MOTION_TRACKING_FILES/\" + os.path.splitext(os.path.basename(video_path))[0] + \"_keypoints.csv\"\n",
    "df.to_csv(csv_file_name, index=False)\n",
    "print(f\"DataFrame saved as {csv_file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
