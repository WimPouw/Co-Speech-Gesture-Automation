{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong>3b: Apex Only Notebook |</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_5003_phase = pd.read_csv('C:/Users/cosmo/Desktop/Random Scripts/Co-Speech Gesture Automation/Co-Speech-Gesture-Automation/ELAN_FILES/5003_I_phase_tier.csv')\n",
    "df_5003_processed = pd.read_csv('C:/Users/cosmo/Desktop/Random Scripts/Co-Speech Gesture Automation/Co-Speech-Gesture-Automation/SPEED_FILES/5003_I_board_one_right_wrist_processed_data.csv')\n",
    "output = 'C:/Users/cosmo/Desktop/Random Scripts/Co-Speech Gesture Automation/Co-Speech-Gesture-Automation/5003_I_board_one_apexes.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original R code for the unwrapper was a function so I reversed engineered it as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_phase(df_phase, df_processed):\n",
    "    aligned_phase = []\n",
    "    gesture_id = int(1)  # initialize gesture_id to 1\n",
    "    gesture_id_list = []  # create an empty list to store gesture_id values\n",
    "    phase_iter = iter(df_phase.itertuples())\n",
    "    current_phase_row = next(phase_iter)\n",
    "    \n",
    "    for row in df_processed.itertuples():\n",
    "        time_ms = row.time_ms\n",
    "        while current_phase_row is not None and time_ms > current_phase_row._2:  # _2 corresponds to 'End Time'\n",
    "            try:\n",
    "                current_phase_row = next(phase_iter)\n",
    "                gesture_id += int(1)  # increment gesture_id for each new annotation instance\n",
    "            except StopIteration:\n",
    "                current_phase_row = None\n",
    "                \n",
    "        if current_phase_row is not None and time_ms >= current_phase_row._1:  # _1 corresponds to 'Begin Time'\n",
    "            aligned_phase.append(current_phase_row._3)  # append Gesture Phase value\n",
    "            gesture_id_list.append(gesture_id)  # append gesture_id value to the list\n",
    "        else:\n",
    "            aligned_phase.append(None)  # append None for Gesture Phase value\n",
    "            gesture_id_list.append(None)  # append None for gesture_id value\n",
    "    \n",
    "    df_processed['gesture_id'] = gesture_id_list  # add gesture_id list as a new column to df_processed\n",
    "    return aligned_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5003_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaned the data since I haven't integrated it earlier in the workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add and align the 'phase' column\n",
    "df_5003_processed['phase'] = align_phase(df_5003_phase, df_5003_processed)\n",
    "\n",
    "# Keep only certain columns\n",
    "df_5003_processed = df_5003_processed.loc[:, ['time_ms', 'speed_smooth', 'gesture_id', 'phase']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more cleaning and the algorithm for the first peak detected within the stroke boundary and then marking it as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where 'speed_smooth' and 'phase' are not null\n",
    "filtered_df = df_5003_processed.dropna(subset=['speed_smooth', 'phase'])\n",
    "\n",
    "# Initialize a new empty DataFrame to hold the more refined annotations\n",
    "more_refined_apexes_df = pd.DataFrame(columns=['time_ms', 'speed_smooth', 'gesture_id', 'apex'])\n",
    "\n",
    "# Loop through each unique gesture_id\n",
    "for gesture_id in filtered_df['gesture_id'].dropna().unique():\n",
    "    # Filter data for the current gesture_id\n",
    "    gesture_data = filtered_df[filtered_df['gesture_id'] == gesture_id]\n",
    "    \n",
    "    # Further filter to get data points where phase is 'S' or 'Stroke'\n",
    "    stroke_data = gesture_data[gesture_data['phase'].isin(['S', 'Stroke'])]\n",
    "    \n",
    "    # Continue to next iteration if no 'Stroke' phase exists for this gesture_id\n",
    "    if len(stroke_data) == 0:\n",
    "        continue\n",
    "\n",
    "    # Dynamically set the large peak threshold for this stroke phase\n",
    "    dynamic_large_peak_threshold = stroke_data['speed_smooth'].mean() + stroke_data['speed_smooth'].std()\n",
    "\n",
    "    # Find peaks within this 'Stroke' phase above the dynamic threshold\n",
    "    peaks, _ = find_peaks(stroke_data['speed_smooth'].values, height=dynamic_large_peak_threshold)\n",
    "    \n",
    "    # If a large peak is found, search for the minimum speed after it\n",
    "    if len(peaks) > 0:\n",
    "        for peak in peaks:\n",
    "            subsequent_data = stroke_data['speed_smooth'].values[peak:]\n",
    "            if len(subsequent_data) > 1:\n",
    "                min_speed_index = np.argmin(subsequent_data) + peak\n",
    "                # Map the min_speed_index to the original DataFrame's index\n",
    "                original_index = stroke_data.index[min_speed_index]\n",
    "                stroke_data.loc[original_index, 'apex'] = 'AX'\n",
    "            \n",
    "    # Append this stroke_data to more_refined_apexes_df\n",
    "    more_refined_apexes_df = more_refined_apexes_df.append(stroke_data)\n",
    "\n",
    "###################### I disabled the plotting code below because it was being annoying and so I was just subsetting it. It's too dense to see much anyway ######################\n",
    "\n",
    "# # Sample the annotated data for plotting\n",
    "# sampled_more_refined_annotated_df = more_refined_apexes_df.dropna(subset=['apex']).sample(frac=0.2, random_state=1)\n",
    "\n",
    "# # Plotting with more refined annotations along with speed curve\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# plt.plot(filtered_df['time_ms'], filtered_df['speed_smooth'], label='Speed Smooth Curve', alpha=0.7)\n",
    "\n",
    "# # Plot the apexes on the speed curve\n",
    "# plt.scatter(sampled_more_refined_annotated_df['time_ms'], sampled_more_refined_annotated_df['speed_smooth'], c='purple', label='Apexes', alpha=0.7, zorder=5)\n",
    "\n",
    "# # Annotate sampled apexes\n",
    "# for i, txt in enumerate(sampled_more_refined_annotated_df['apex']):\n",
    "#     plt.annotate(txt, (sampled_more_refined_annotated_df['time_ms'].iloc[i], sampled_more_refined_annotated_df['speed_smooth'].iloc[i]), fontsize=8, alpha=0.7)\n",
    "\n",
    "# plt.title('Speed Smooth Curve with More Refined Apex Annotations')\n",
    "# plt.xlabel('Time (ms)')\n",
    "# plt.ylabel('Speed (Smoothed)')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "more_refined_apexes_df.to_csv(output, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
